---
title: "p8105_hw5_yw3439"
author: "Qetsiyah Wang"
date: "11/15/2020"
output: github_document
---

```{r setup, include=FALSE}
knitr::opts_chunk$set(echo = TRUE,
                      message = FALSE,
                      warning = FALSE, fig.height = 6, fig.width = 8)

library(tidyverse)
library(dplyr)
```

# Problem 1 - Washington Homicides

```{r}
homicide = read_csv("homicide-data.csv")
```
  The raw dataset contains `r ncol(homicide)` variables and `r nrow(homicide)` observations. Major variables contain: information about victims in each homicide, including their names, `r str_remove(colnames(homicide)[5:7], pattern = "victim_")`, and reported case information, such as `r colnames(homicide)[8:12]` and `r colnames(homicide)[2]`. 

```{r}

cases = homicide %>%
  mutate(
    city_state = paste(city, ",", state)
  ) %>%
  select(-city, -state) %>%
  group_by(city_state, disposition) %>%
  summarize(n = n()) %>%
  pivot_wider(
    names_from = disposition,
    values_from = n
  ) %>%
  janitor::clean_names() %>%
  mutate(
    total_cases = sum(closed_by_arrest, closed_without_arrest, open_no_arrest, na.rm = TRUE),
    unsolved_cases = sum(closed_without_arrest, open_no_arrest, na.rm = TRUE)
  ) %>%
  select(-closed_by_arrest, -closed_without_arrest, -open_no_arrest)

knitr::kables(cases, caption = "Homicides for Each City-State")

```


```{r}

baltimore = cases %>%
  filter(city_state == "Baltimore , MD") %>%
  as.list()

baltimore_prop = prop.test(x = baltimore[["unsolved_cases"]], n = baltimore[["total_cases"]]) %>%
  broom::tidy() %>%
  select(estimate, conf.low, conf.high)
  
knitr::kables(baltimore_prop, caption = "Unsolved Homicides for Baltimore")
```
  With proportion test of homicide cases in Baltimore, MD, the estimate proportion is `r round(pull(baltimore_prop, estimate), 2)` and the confidence level for the test is (`r round(pull(baltimore_prop, conf.low, 2))`, `r round(pull(baltimore_prop, conf.high, 2))`).
  
```{r}

propor = function(unsolved, total) {
  
  prop.test(x = unsolved, n = total) %>%
    broom::tidy() %>%
    select(estimate, conf.low, conf.high)
}

cases_test = cases[2:3]
  
  
cases_test = cases_test %>%
  mutate(
    output = map2(.x = cases_test$unsolved_cases, .y = cases_test$total_cases, 
                  ~ propor(unsolved = .x, total = .y)),
    result = map(output, bind_rows)
  ) %>%
  select(-output) %>%
  unnest(result)

cases_test = cases_test %>%
  mutate(
    city_state = pull(cases, city_state)
  ) %>%
  select(city_state, estimate, conf.low, conf.high)

knitr::kable(cases_test, caption = "Estimated Proportion of Unsolved Homicides for Each City-State")

```


  Proportion test for each cities about unsolved homicide cases are shown in the table above.

```{r}

cases_test %>%
  arrange(-estimate) %>% 
  mutate(
  city_state = fct_reorder(city_state, estimate))%>%
  ggplot(aes(x = city_state, y = estimate, ymin = conf.low, ymax = conf.high)) +
  geom_errorbar(width = 0.5) +
  coord_flip() +
  labs(
    title = "Estimated Proportion of Unsolved Homicides for Each City-State",
    x = "Estimate Proportion of Unsolved Homicides",
    y = "City and State"
  )

```


# Probelm 2

```{r}

file = list.files("./data/", recursive= TRUE, full.names = TRUE) 

study = purrr::map(file, ~ read.csv(.)) %>%
  reduce(rbind) %>%
  mutate(
    subject_id = rep(c(1:10),2)
  ) %>%
  arrange(subject_id) %>%
  mutate(
    arm = rep(c("control", "experiment"), 10))

knitr::kable(study)

study %>%
  pivot_longer(
    week_1 : week_8,
    names_to = "week",
    values_to = "observations",
    names_prefix = "week_"
  ) %>%
  mutate(
    week = as.numeric(week),
    subject_id = as.factor(subject_id)
  ) %>%
  ggplot(aes(x = week, y = observations, color = subject_id)) +
  geom_line() +
  facet_grid(~arm) +
  labs(
    title = "Observations on each subject over time within Control and Experimental group",
    x = "Week",
    y = "Observations"
  )

```
  For the whole study period, two groups both show fluctuations within each week. Even though with fluctuations, the control group finally maintains the level of observations for each subject showing no big difference between the starting point and the end point. For example, the subject 5, presenting the lowest observation of `r pull(study, week_6)[8]` shows the difference of observation between the start and end is `r pull(study, week_8)[8] - pull(study, week_1)[8]`. 
  
  Unlike the control group, the experimental group represented the overall significantly increasing trend in observations across the whole study period. Subject 5 in the experimental group showed the difference across the experiment period of `n pull(study, week_8)[9] - pull(study, week_1)[9]`. Comparing with the result shown for the same subject in the control arm, the interest of the study shows a significant impact in positive correlation for participants. 
  
# Problem 3

```{r}

sim_test = function(n = 30, sigma = 5, mu) {
  
  x = rnorm(n = n, mean = mu, sd = sigma)
  
  t_test = t.test(x = x, alternative = "two.sided", conf.level = 0.95) %>%
    broom::tidy() %>%
    select(estimate, p.value)
}

mu_0 = rerun(5000, sim_test(mu = 0)) %>%
  bind_rows()

mu_test = tibble(
  mu = c(1, 2, 3, 4, 5, 6)) %>%
  mutate(
    output = map(.x = mu, ~ rerun(5000, sim_test(mu = .x))),
    result = map(output, bind_rows)
  ) %>%
  select(-output) %>%
  unnest()
```

```{r}

mu_test %>%
  filter(p.value < 0.05) %>%
  group_by(mu) %>%
  summarize(proportion = length(p.value)/5000) %>%
  ggplot(aes(x = mu, y = proportion), xlim) +
  geom_point() +
  geom_smooth() +
  labs(
    title = "Association between Power and Effect size",
    x = "Effect size of mu",
    y = "Power of test"
  )
  
```

  Based on the plot shown above, the association between effect size of mu and the power of the test is positive correlated. When the effect size of mu increases, more amount of the null would be rejected and the power of the test increases. Because with the effect size of mean increases, the magnitude of difference between true mean and the null increases the probability of rejecting the null while the alternative hypothesis is right. With the sensitivity increases, the power of the test increases. Same conclusion can be addressed from the plot, as the effect size of mu approaches to 6, the power of the test is equal to 1.

```{r}

all_mu = mu_test %>%
  group_by(mu) %>%
  summarise(
    mean_estimate = mean(estimate, na.rm = TRUE)
  )

rejected_null = mu_test %>%
  filter(p.value < 0.05) %>%
  group_by(mu) %>%
  summarise(
    average_estimate = mean(estimate, na.rm = TRUE)
  )

ggplot(all_mu, aes(x = mu, y = mean_estimate)) +
  geom_point(aes(color = "All mu")) +
  geom_line(aes(color = "All mu")) +
  labs(
    title = "Association between True Value and Average Estimate of mu",
    x = "True Value of Estimated mu",
    y = "Average of Estimated mu"
  ) +
  geom_line(data = rejected_null, aes(x = mu, y = average_estimate, color = "Rejected mu")) +
  geom_point(data = rejected_null, aes(x = mu, y = average_estimate, color = "Rejected mu"))


```
   
   Shown in the plot above, average of all values of mu will be equal to true value of mu, following the expectation rule for probability. As the effect size of mu increases, the magnitude of difference between the null and true mean increases, so that the proportion of rejected null decreases. In other words, more values of estimated mu get approached to the true mu. Same observations can be concluded from the plot that the average of estimated mu within rejected null approximates to all mu, which fits with the plot result from the figure of "Association between Power and Effect Size".




